{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gqxSKZJbLBr2",
        "wu5vqxHDMzSy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#FP-Growth\n"
      ],
      "metadata": {
        "id": "gqxSKZJbLBr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, Iterable, Iterator, List, Optional, Tuple, FrozenSet\n",
        "\n",
        "\n",
        "# FP-tree node and tree classes\n",
        "@dataclass\n",
        "class FPNode:\n",
        "    item: Optional[Any]\n",
        "    count: int\n",
        "    parent: Optional['FPNode'] = None\n",
        "    children: Dict[Any, 'FPNode'] = field(default_factory=dict)\n",
        "    node_link: Optional['FPNode'] = None\n",
        "\n",
        "    def increment(self, n: int = 1) -> None:\n",
        "        \"\"\"Increase node count by n (used when merging counts).\"\"\"\n",
        "        self.count += n\n",
        "\n",
        "\n",
        "class FPTree:\n",
        "    \"\"\"Container for the FP-tree and its header table.\n",
        "    header_table maps item -> (support_count, first_node)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.root = FPNode(None, 1)\n",
        "        self.header_table: Dict[Any, Tuple[int, Optional[FPNode]]] = {}\n",
        "\n",
        "    def add_transaction(self, transaction: List[Any], count: int = 1) -> None:\n",
        "        \"\"\"Insert a single (ordered) transaction into the tree with given count.\n",
        "        Count is added to existing node counts instead of inserting multiple copies.\n",
        "        \"\"\"\n",
        "        node = self.root\n",
        "        for item in transaction:\n",
        "            if item in node.children:\n",
        "                # existing child: increment its count\n",
        "                child = node.children[item]\n",
        "                child.increment(count)\n",
        "                node = child\n",
        "            else:\n",
        "                # create a new child node and link it in header table\n",
        "                new_node = FPNode(item, count, parent=node)\n",
        "                node.children[item] = new_node\n",
        "                self._update_header(item, new_node, count)\n",
        "                node = new_node\n",
        "\n",
        "    def _update_header(self, item: Any, new_node: FPNode, count: int) -> None:\n",
        "        \"\"\"Update header table count and append node to node_link chain.\"\"\"\n",
        "        if item in self.header_table:\n",
        "            total, first = self.header_table[item]\n",
        "            # append new_node at end of node_link chain\n",
        "            if first is None:\n",
        "                self.header_table[item] = (total + count, new_node)\n",
        "            else:\n",
        "                last = first\n",
        "                while last.node_link is not None:\n",
        "                    last = last.node_link\n",
        "                last.node_link = new_node\n",
        "                self.header_table[item] = (total + count, first)\n",
        "        else:\n",
        "            self.header_table[item] = (count, new_node)\n",
        "\n",
        "    def conditional_pattern_base(self, item: Any) -> List[Tuple[List[Any], int]]:\n",
        "        \"\"\"Return conditional pattern base as list of (prefix_path, count).\n",
        "        Each prefix_path is the sequence of items from root (excluded) to\n",
        "        the parent of a node with 'item'. Counts reflect how many times the\n",
        "        path appears with 'item'.\n",
        "        \"\"\"\n",
        "        base_patterns: List[Tuple[List[Any], int]] = []\n",
        "        if item not in self.header_table:\n",
        "            return base_patterns\n",
        "        _, node = self.header_table[item]\n",
        "        while node is not None:\n",
        "            count = node.count\n",
        "            path: List[Any] = []\n",
        "            parent = node.parent\n",
        "            # traverse to root, collecting items\n",
        "            while parent is not None and parent.item is not None:\n",
        "                path.append(parent.item)\n",
        "                parent = parent.parent\n",
        "            if path:\n",
        "                base_patterns.append((list(reversed(path)), count))\n",
        "            node = node.node_link\n",
        "\n",
        "        return base_patterns\n",
        "\n",
        "    def has_single_path(self) -> bool:\n",
        "        \"\"\"Check if the tree (excluding root) is a single path.\n",
        "        If single path, frequent patterns can be generated combinatorially.\n",
        "        \"\"\"\n",
        "        node = self.root\n",
        "        return self._is_single_path_from(node)\n",
        "\n",
        "    def _is_single_path_from(self, node: FPNode) -> bool:\n",
        "        if len(node.children) > 1:\n",
        "            return False\n",
        "        if len(node.children) == 0:\n",
        "            return True\n",
        "        # continue down the single child\n",
        "        child = next(iter(node.children.values()))\n",
        "        return self._is_single_path_from(child)\n",
        "\n",
        "\n",
        "# FP-Growth core functions\n",
        "def _sort_items_by_frequency(items: Iterable[Any], freq: Dict[Any, int]) -> List[Any]:\n",
        "    \"\"\"Return items sorted by descending frequency, then by item for stability.\"\"\"\n",
        "    return sorted(items, key=lambda it: (-freq[it], it))\n",
        "\n",
        "\n",
        "def build_fptree_from_paths(paths: List[Tuple[List[Any], int]], min_support: int) -> Tuple[FPTree, Dict[Any, int]]:\n",
        "    \"\"\"Build an FP-tree from conditional paths (each with a count).\n",
        "    Paths are list of (ordered_items, count). This avoids expanding counts.\n",
        "    Returns the built tree and the frequency dict (filtered by min_support).\n",
        "    \"\"\"\n",
        "    # aggregate item counts from paths\n",
        "    item_counts: Counter = Counter()\n",
        "    for path, count in paths:\n",
        "        for item in path:\n",
        "            item_counts[item] += count\n",
        "    # filter infrequent items\n",
        "    freq_items = {item: cnt for item, cnt in item_counts.items() if cnt >= min_support}\n",
        "    tree = FPTree()\n",
        "    if not freq_items:\n",
        "        return tree, {}\n",
        "    # initialize header counts (node pointers set in add_transaction)\n",
        "    for item, cnt in freq_items.items():\n",
        "        tree.header_table[item] = (cnt, None)\n",
        "    # insert filtered & ordered transactions\n",
        "    for path, count in paths:\n",
        "        ordered = [it for it in path if it in freq_items]\n",
        "        if not ordered:\n",
        "            continue\n",
        "        ordered = _sort_items_by_frequency(ordered, freq_items)\n",
        "        tree.add_transaction(ordered, count)\n",
        "    return tree, freq_items\n",
        "\n",
        "\n",
        "def build_fptree(transactions: List[List[Any]], min_support: int) -> Tuple[FPTree, Dict[Any, int]]:\n",
        "    \"\"\"Build FP-tree from raw transactions (each considered count=1).\n",
        "    This is a convenience wrapper that converts transactions into paths\n",
        "    with counts and calls build_fptree_from_paths.\n",
        "    \"\"\"\n",
        "    paths_with_counts: List[Tuple[List[Any], int]] = [(trans, 1) for trans in transactions]\n",
        "    return build_fptree_from_paths(paths_with_counts, min_support)\n",
        "\n",
        "\n",
        "def mine_fp_tree(tree: FPTree, min_support: int) -> Dict[FrozenSet[Any], int]:\n",
        "    \"\"\"Mine the FP-tree and return frequent itemsets with their supports.\n",
        "    This function returns a mapping: frozenset(itemset) -> support_count.\n",
        "    \"\"\"\n",
        "    patterns: Dict[FrozenSet[Any], int] = {}\n",
        "    # items sorted by ascending support (least frequent first) for mining\n",
        "    items = sorted(tree.header_table.items(), key=lambda x: (x[1][0], x[0]))\n",
        "\n",
        "    for item, (support, _) in items:\n",
        "        # single item pattern\n",
        "        patterns[frozenset([item])] = support\n",
        "        # build conditional pattern base for item\n",
        "        cpb = tree.conditional_pattern_base(item)\n",
        "        # build conditional tree from cpb (paths with counts)\n",
        "        cond_tree, cond_freq = build_fptree_from_paths(cpb, min_support)\n",
        "        if not cond_freq:\n",
        "            continue\n",
        "        # if conditional tree has single path, generate combinations directly\n",
        "        if cond_tree.has_single_path():\n",
        "            # collect path items and their counts\n",
        "            single_path: List[Tuple[Any, int]] = []\n",
        "            node = cond_tree.root\n",
        "            while node and node.children:\n",
        "                # exactly one child per level\n",
        "                child = next(iter(node.children.values()))\n",
        "                single_path.append((child.item, child.count))\n",
        "                node = child\n",
        "            # generate all combinations of items in path with min count as support\n",
        "            n = len(single_path)\n",
        "            from itertools import combinations\n",
        "\n",
        "            for r in range(1, n + 1):\n",
        "                for combo in combinations(single_path, r):\n",
        "                    combo_items = frozenset([it for it, _ in combo])\n",
        "                    combo_support = min(cnt for _, cnt in combo)\n",
        "                    new_pattern = frozenset(set(combo_items) | {item})\n",
        "                    patterns[new_pattern] = max(patterns.get(new_pattern, 0), combo_support)\n",
        "        else:\n",
        "            # recursively mine conditional tree\n",
        "            sub_patterns = mine_fp_tree(cond_tree, min_support)\n",
        "            for pset, psup in sub_patterns.items():\n",
        "                new_pattern = frozenset(set(pset) | {item})\n",
        "                patterns[new_pattern] = max(patterns.get(new_pattern, 0), psup)\n",
        "\n",
        "    return patterns\n",
        "\n",
        "\n",
        "def fp_growth(transactions: List[List[Any]], min_support: int) -> Dict[FrozenSet[Any], int]:\n",
        "    \"\"\"Top-level FP-Growth function.\n",
        "    Returns frequent itemsets -> support counts.\n",
        "    \"\"\"\n",
        "    tree, freq_items = build_fptree(transactions, min_support)\n",
        "    if not freq_items:\n",
        "        return {}\n",
        "    patterns = mine_fp_tree(tree, min_support)\n",
        "    # ensure single-item supports are present and correct\n",
        "    for it, cnt in freq_items.items():\n",
        "        patterns.setdefault(frozenset([it]), cnt)\n",
        "    return patterns\n",
        "\n",
        "\n",
        "# Association rule generation\n",
        "def generate_association_rules(patterns: Dict[FrozenSet[Any], int], min_confidence: float) -> List[Tuple[set, set, float, int]]:\n",
        "    \"\"\"Generate association rules from frequent itemsets.\n",
        "    Returns list of tuples: (antecedent_set, consequent_set, confidence, support_count_of_whole).\n",
        "    \"\"\"\n",
        "    rules: List[Tuple[set, set, float, int]] = []\n",
        "    # helper to generate non-empty proper subsets\n",
        "    def _subsets(s: List[Any]) -> Iterator[Tuple[Any, ...]]:\n",
        "        from itertools import chain, combinations\n",
        "\n",
        "        for r in range(1, len(s)):\n",
        "            for combo in combinations(s, r):\n",
        "                yield combo\n",
        "\n",
        "    for itemset, sup in patterns.items():\n",
        "        if len(itemset) < 2:\n",
        "            continue\n",
        "        items_list = list(itemset)\n",
        "        for subset in _subsets(items_list):\n",
        "            A = frozenset(subset)\n",
        "            B = itemset - A\n",
        "            if A not in patterns:\n",
        "                continue\n",
        "            support_A = patterns[A]\n",
        "            confidence = sup / support_A\n",
        "            if confidence >= min_confidence:\n",
        "                rules.append((set(A), set(B), confidence, sup))\n",
        "    # sort by confidence then support\n",
        "\n",
        "    rules.sort(key=lambda x: (-x[2], -x[3]))\n",
        "    return rules\n",
        "\n",
        "\n",
        "# Simple demo when run as script\n",
        "if __name__ == '__main__':\n",
        "    # example transactions\n",
        "    transactions = [\n",
        "        ['f', 'a', 'c', 'd', 'g', 'i', 'm', 'p'],\n",
        "        ['a', 'b', 'c', 'f', 'l', 'm', 'o'],\n",
        "        ['b', 'f', 'h', 'j', 'o'],\n",
        "        ['b', 'c', 'k', 's', 'p'],\n",
        "        ['a', 'f', 'c', 'e', 'l', 'p', 'm', 'n'],\n",
        "    ]\n",
        "\n",
        "    min_support = 2\n",
        "    patterns = fp_growth(transactions, min_support)\n",
        "    print('Frequent patterns (itemset -> support):')\n",
        "    for itset, sup in sorted(patterns.items(), key=lambda x: (-len(x[0]), -x[1], sorted(list(x[0])))):\n",
        "        print(set(itset), '->', sup)\n",
        "\n",
        "    rules = generate_association_rules(patterns, min_confidence=0.6)\n",
        "    print('\\nGenerated rules (A => B, confidence, support):')\n",
        "    for A, B, conf, sup in rules:\n",
        "        print(f'{A} => {B}, conf={conf:.2f}, sup={sup}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebwVYCTMKfnw",
        "outputId": "9ce39c23-cef6-4d0b-84b7-cea803f9b24b"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent patterns (itemset -> support):\n",
            "{'f', 'm', 'l', 'a', 'c'} -> 2\n",
            "{'f', 'm', 'p', 'a', 'c'} -> 2\n",
            "{'a', 'f', 'm', 'c'} -> 3\n",
            "{'a', 'f', 'l', 'c'} -> 2\n",
            "{'a', 'f', 'c', 'p'} -> 2\n",
            "{'a', 'm', 'c', 'l'} -> 2\n",
            "{'a', 'm', 'c', 'p'} -> 2\n",
            "{'a', 'f', 'm', 'l'} -> 2\n",
            "{'a', 'f', 'm', 'p'} -> 2\n",
            "{'f', 'm', 'c', 'l'} -> 2\n",
            "{'f', 'm', 'c', 'p'} -> 2\n",
            "{'a', 'f', 'c'} -> 3\n",
            "{'a', 'm', 'c'} -> 3\n",
            "{'a', 'f', 'm'} -> 3\n",
            "{'f', 'm', 'c'} -> 3\n",
            "{'a', 'l', 'c'} -> 2\n",
            "{'a', 'c', 'p'} -> 2\n",
            "{'a', 'f', 'l'} -> 2\n",
            "{'a', 'f', 'p'} -> 2\n",
            "{'a', 'm', 'l'} -> 2\n",
            "{'a', 'm', 'p'} -> 2\n",
            "{'o', 'f', 'b'} -> 2\n",
            "{'f', 'l', 'c'} -> 2\n",
            "{'f', 'c', 'p'} -> 2\n",
            "{'m', 'c', 'l'} -> 2\n",
            "{'m', 'c', 'p'} -> 2\n",
            "{'f', 'm', 'l'} -> 2\n",
            "{'f', 'm', 'p'} -> 2\n",
            "{'f', 'b'} -> 4\n",
            "{'a', 'c'} -> 3\n",
            "{'a', 'f'} -> 3\n",
            "{'a', 'm'} -> 3\n",
            "{'b', 'c'} -> 3\n",
            "{'f', 'c'} -> 3\n",
            "{'m', 'c'} -> 3\n",
            "{'c', 'p'} -> 3\n",
            "{'f', 'm'} -> 3\n",
            "{'a', 'l'} -> 2\n",
            "{'a', 'p'} -> 2\n",
            "{'o', 'b'} -> 2\n",
            "{'l', 'c'} -> 2\n",
            "{'f', 'l'} -> 2\n",
            "{'o', 'f'} -> 2\n",
            "{'f', 'p'} -> 2\n",
            "{'m', 'l'} -> 2\n",
            "{'m', 'p'} -> 2\n",
            "{'b'} -> 6\n",
            "{'f'} -> 6\n",
            "{'c'} -> 5\n",
            "{'m'} -> 5\n",
            "{'p'} -> 5\n",
            "{'a'} -> 4\n",
            "{'l'} -> 4\n",
            "{'o'} -> 4\n",
            "\n",
            "Generated rules (A => B, confidence, support):\n",
            "{'a', 'f'} => {'c'}, conf=1.00, sup=3\n",
            "{'a', 'c'} => {'f'}, conf=1.00, sup=3\n",
            "{'f', 'c'} => {'a'}, conf=1.00, sup=3\n",
            "{'a', 'm'} => {'c'}, conf=1.00, sup=3\n",
            "{'a', 'c'} => {'m'}, conf=1.00, sup=3\n",
            "{'m', 'c'} => {'a'}, conf=1.00, sup=3\n",
            "{'a', 'f'} => {'m'}, conf=1.00, sup=3\n",
            "{'a', 'm'} => {'f'}, conf=1.00, sup=3\n",
            "{'f', 'm'} => {'a'}, conf=1.00, sup=3\n",
            "{'f', 'm'} => {'c'}, conf=1.00, sup=3\n",
            "{'f', 'c'} => {'m'}, conf=1.00, sup=3\n",
            "{'m', 'c'} => {'f'}, conf=1.00, sup=3\n",
            "{'a', 'f'} => {'m', 'c'}, conf=1.00, sup=3\n",
            "{'a', 'm'} => {'f', 'c'}, conf=1.00, sup=3\n",
            "{'a', 'c'} => {'f', 'm'}, conf=1.00, sup=3\n",
            "{'f', 'm'} => {'a', 'c'}, conf=1.00, sup=3\n",
            "{'f', 'c'} => {'a', 'm'}, conf=1.00, sup=3\n",
            "{'m', 'c'} => {'a', 'f'}, conf=1.00, sup=3\n",
            "{'a', 'f', 'm'} => {'c'}, conf=1.00, sup=3\n",
            "{'a', 'f', 'c'} => {'m'}, conf=1.00, sup=3\n",
            "{'a', 'm', 'c'} => {'f'}, conf=1.00, sup=3\n",
            "{'f', 'm', 'c'} => {'a'}, conf=1.00, sup=3\n",
            "{'a', 'l'} => {'c'}, conf=1.00, sup=2\n",
            "{'l', 'c'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'l'} => {'f'}, conf=1.00, sup=2\n",
            "{'f', 'l'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'l'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'l'} => {'a'}, conf=1.00, sup=2\n",
            "{'f', 'l'} => {'c'}, conf=1.00, sup=2\n",
            "{'l', 'c'} => {'f'}, conf=1.00, sup=2\n",
            "{'m', 'l'} => {'c'}, conf=1.00, sup=2\n",
            "{'l', 'c'} => {'m'}, conf=1.00, sup=2\n",
            "{'f', 'l'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'l'} => {'f'}, conf=1.00, sup=2\n",
            "{'a', 'l'} => {'f', 'c'}, conf=1.00, sup=2\n",
            "{'f', 'l'} => {'a', 'c'}, conf=1.00, sup=2\n",
            "{'l', 'c'} => {'a', 'f'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'l'} => {'c'}, conf=1.00, sup=2\n",
            "{'a', 'l', 'c'} => {'f'}, conf=1.00, sup=2\n",
            "{'f', 'l', 'c'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'l'} => {'m', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'l'} => {'a', 'c'}, conf=1.00, sup=2\n",
            "{'l', 'c'} => {'a', 'm'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'l'} => {'c'}, conf=1.00, sup=2\n",
            "{'a', 'l', 'c'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'c', 'l'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'l'} => {'f', 'm'}, conf=1.00, sup=2\n",
            "{'f', 'l'} => {'a', 'm'}, conf=1.00, sup=2\n",
            "{'m', 'l'} => {'a', 'f'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'l'} => {'m'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'l'} => {'f'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'l'} => {'a'}, conf=1.00, sup=2\n",
            "{'f', 'l'} => {'m', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'l'} => {'f', 'c'}, conf=1.00, sup=2\n",
            "{'l', 'c'} => {'f', 'm'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'l'} => {'c'}, conf=1.00, sup=2\n",
            "{'f', 'l', 'c'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'c', 'l'} => {'f'}, conf=1.00, sup=2\n",
            "{'f', 'l'} => {'a', 'm', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'l'} => {'a', 'f', 'c'}, conf=1.00, sup=2\n",
            "{'a', 'l'} => {'f', 'm', 'c'}, conf=1.00, sup=2\n",
            "{'l', 'c'} => {'a', 'f', 'm'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'l'} => {'a', 'c'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'l'} => {'m', 'c'}, conf=1.00, sup=2\n",
            "{'f', 'l', 'c'} => {'a', 'm'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'l'} => {'f', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'c', 'l'} => {'a', 'f'}, conf=1.00, sup=2\n",
            "{'a', 'l', 'c'} => {'f', 'm'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'm', 'l'} => {'c'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'c', 'l'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'l', 'c'} => {'m'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'c', 'l'} => {'f'}, conf=1.00, sup=2\n",
            "{'o', 'f'} => {'b'}, conf=1.00, sup=2\n",
            "{'o', 'b'} => {'f'}, conf=1.00, sup=2\n",
            "{'a', 'p'} => {'c'}, conf=1.00, sup=2\n",
            "{'f', 'p'} => {'c'}, conf=1.00, sup=2\n",
            "{'m', 'p'} => {'c'}, conf=1.00, sup=2\n",
            "{'a', 'p'} => {'f'}, conf=1.00, sup=2\n",
            "{'f', 'p'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'p'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'p'} => {'a'}, conf=1.00, sup=2\n",
            "{'f', 'p'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'p'} => {'f'}, conf=1.00, sup=2\n",
            "{'a', 'p'} => {'f', 'c'}, conf=1.00, sup=2\n",
            "{'f', 'p'} => {'a', 'c'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'p'} => {'c'}, conf=1.00, sup=2\n",
            "{'a', 'c', 'p'} => {'f'}, conf=1.00, sup=2\n",
            "{'f', 'c', 'p'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'p'} => {'m', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'p'} => {'a', 'c'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'p'} => {'c'}, conf=1.00, sup=2\n",
            "{'a', 'c', 'p'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'c', 'p'} => {'a'}, conf=1.00, sup=2\n",
            "{'f', 'p'} => {'m', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'p'} => {'f', 'c'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'p'} => {'c'}, conf=1.00, sup=2\n",
            "{'f', 'c', 'p'} => {'m'}, conf=1.00, sup=2\n",
            "{'m', 'c', 'p'} => {'f'}, conf=1.00, sup=2\n",
            "{'a', 'p'} => {'f', 'm'}, conf=1.00, sup=2\n",
            "{'f', 'p'} => {'a', 'm'}, conf=1.00, sup=2\n",
            "{'m', 'p'} => {'a', 'f'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'p'} => {'m'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'p'} => {'f'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'p'} => {'a'}, conf=1.00, sup=2\n",
            "{'f', 'p'} => {'a', 'm', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'p'} => {'a', 'f', 'c'}, conf=1.00, sup=2\n",
            "{'a', 'p'} => {'f', 'm', 'c'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'p'} => {'a', 'c'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'p'} => {'m', 'c'}, conf=1.00, sup=2\n",
            "{'f', 'p', 'c'} => {'a', 'm'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'p'} => {'f', 'c'}, conf=1.00, sup=2\n",
            "{'m', 'p', 'c'} => {'a', 'f'}, conf=1.00, sup=2\n",
            "{'a', 'p', 'c'} => {'f', 'm'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'm', 'p'} => {'c'}, conf=1.00, sup=2\n",
            "{'f', 'm', 'p', 'c'} => {'a'}, conf=1.00, sup=2\n",
            "{'a', 'f', 'p', 'c'} => {'m'}, conf=1.00, sup=2\n",
            "{'a', 'm', 'p', 'c'} => {'f'}, conf=1.00, sup=2\n",
            "{'a'} => {'c'}, conf=0.75, sup=3\n",
            "{'a'} => {'f'}, conf=0.75, sup=3\n",
            "{'a'} => {'f', 'c'}, conf=0.75, sup=3\n",
            "{'a'} => {'m'}, conf=0.75, sup=3\n",
            "{'a'} => {'m', 'c'}, conf=0.75, sup=3\n",
            "{'a'} => {'f', 'm'}, conf=0.75, sup=3\n",
            "{'a'} => {'f', 'm', 'c'}, conf=0.75, sup=3\n",
            "{'f'} => {'b'}, conf=0.67, sup=4\n",
            "{'b'} => {'f'}, conf=0.67, sup=4\n",
            "{'a', 'c'} => {'l'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'l'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'l'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'l'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'l'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'l'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'l', 'c'}, conf=0.67, sup=2\n",
            "{'a', 'c'} => {'f', 'l'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'a', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'c'} => {'l'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'l', 'c'}, conf=0.67, sup=2\n",
            "{'a', 'c'} => {'m', 'l'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'a', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'm', 'c'} => {'l'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'m', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'f', 'l'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'a', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'm'} => {'l'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'l', 'c'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'m', 'l'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'f', 'l'}, conf=0.67, sup=2\n",
            "{'f', 'm', 'c'} => {'l'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'a', 'l', 'c'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'m', 'c', 'l'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'a', 'm', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'f', 'l', 'c'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'a', 'f', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'c'} => {'f', 'm', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'm'} => {'l', 'c'}, conf=0.67, sup=2\n",
            "{'f', 'm', 'c'} => {'a', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'c'} => {'m', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'm', 'c'} => {'f', 'l'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'm', 'c'} => {'l'}, conf=0.67, sup=2\n",
            "{'a', 'c'} => {'p'}, conf=0.67, sup=2\n",
            "{'c', 'p'} => {'a'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'p'}, conf=0.67, sup=2\n",
            "{'c', 'p'} => {'f'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'p'}, conf=0.67, sup=2\n",
            "{'c', 'p'} => {'m'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'p'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'p'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'p'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'c', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'c'} => {'f', 'p'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'a', 'p'}, conf=0.67, sup=2\n",
            "{'c', 'p'} => {'a', 'f'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'c'} => {'p'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'c', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'c'} => {'m', 'p'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'a', 'p'}, conf=0.67, sup=2\n",
            "{'c', 'p'} => {'a', 'm'}, conf=0.67, sup=2\n",
            "{'a', 'm', 'c'} => {'p'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'c', 'p'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'m', 'p'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'f', 'p'}, conf=0.67, sup=2\n",
            "{'c', 'p'} => {'f', 'm'}, conf=0.67, sup=2\n",
            "{'f', 'm', 'c'} => {'p'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'m', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'f', 'p'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'a', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'm'} => {'p'}, conf=0.67, sup=2\n",
            "{'f', 'm'} => {'a', 'p', 'c'}, conf=0.67, sup=2\n",
            "{'a', 'f'} => {'m', 'p', 'c'}, conf=0.67, sup=2\n",
            "{'f', 'c'} => {'a', 'm', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'm'} => {'f', 'p', 'c'}, conf=0.67, sup=2\n",
            "{'m', 'c'} => {'a', 'f', 'p'}, conf=0.67, sup=2\n",
            "{'p', 'c'} => {'a', 'f', 'm'}, conf=0.67, sup=2\n",
            "{'a', 'c'} => {'f', 'm', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'm'} => {'p', 'c'}, conf=0.67, sup=2\n",
            "{'f', 'm', 'c'} => {'a', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'c'} => {'m', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'm', 'c'} => {'f', 'p'}, conf=0.67, sup=2\n",
            "{'a', 'f', 'm', 'c'} => {'p'}, conf=0.67, sup=2\n",
            "{'c'} => {'a'}, conf=0.60, sup=3\n",
            "{'c'} => {'a', 'f'}, conf=0.60, sup=3\n",
            "{'m'} => {'a'}, conf=0.60, sup=3\n",
            "{'m'} => {'c'}, conf=0.60, sup=3\n",
            "{'c'} => {'m'}, conf=0.60, sup=3\n",
            "{'m'} => {'f'}, conf=0.60, sup=3\n",
            "{'m'} => {'a', 'c'}, conf=0.60, sup=3\n",
            "{'c'} => {'a', 'm'}, conf=0.60, sup=3\n",
            "{'m'} => {'a', 'f'}, conf=0.60, sup=3\n",
            "{'m'} => {'f', 'c'}, conf=0.60, sup=3\n",
            "{'c'} => {'f', 'm'}, conf=0.60, sup=3\n",
            "{'m'} => {'a', 'f', 'c'}, conf=0.60, sup=3\n",
            "{'c'} => {'a', 'f', 'm'}, conf=0.60, sup=3\n",
            "{'c'} => {'p'}, conf=0.60, sup=3\n",
            "{'p'} => {'c'}, conf=0.60, sup=3\n",
            "{'c'} => {'b'}, conf=0.60, sup=3\n",
            "{'c'} => {'f'}, conf=0.60, sup=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-fold cross-validation"
      ],
      "metadata": {
        "id": "wu5vqxHDMzSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Callable, Optional, Any, List\n",
        "\n",
        "\n",
        "def k_fold_indices(n_samples: int, k: int = 5, shuffle: bool = True, random_state: Optional[int] = None) -> List[np.ndarray]:\n",
        "    \"\"\"Return list of k arrays with indices for each fold.\"\"\"\n",
        "    if k <= 1:\n",
        "        raise ValueError(\"k must be >= 2\")\n",
        "    if n_samples < k:\n",
        "        raise ValueError(\"n_samples must be >= k\")\n",
        "\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    indices = np.arange(n_samples)\n",
        "    if shuffle:\n",
        "        rng.shuffle(indices)\n",
        "\n",
        "    base, remainder = divmod(n_samples, k)\n",
        "    folds, start = [], 0\n",
        "    for i in range(k):\n",
        "        size = base + (1 if i < remainder else 0)\n",
        "        folds.append(indices[start:start+size])\n",
        "        start += size\n",
        "    return folds\n",
        "\n",
        "\n",
        "def _as_predictable(model_or_fn: Any) -> Any:\n",
        "    \"\"\"Wrap callable into object with .predict(X).\"\"\"\n",
        "    if callable(model_or_fn):\n",
        "        class _Wrapper:\n",
        "            def __init__(self, fn):\n",
        "                self._fn = fn\n",
        "            def predict(self, X):\n",
        "                return self._fn(X)\n",
        "        return _Wrapper(model_or_fn)\n",
        "    if hasattr(model_or_fn, 'predict'):\n",
        "        return model_or_fn\n",
        "    raise ValueError(\"Learner must return callable or object with .predict(X)\")\n",
        "\n",
        "\n",
        "def cross_validate(X: np.ndarray,\n",
        "                   y: np.ndarray,\n",
        "                   learner: Callable[[np.ndarray, np.ndarray], Any],\n",
        "                   k: int = 5,\n",
        "                   metric: Optional[Callable[[np.ndarray, np.ndarray], float]] = None,\n",
        "                   shuffle: bool = True,\n",
        "                   random_state: Optional[int] = None) -> dict:\n",
        "    \"\"\"Perform k-fold cross validation.\"\"\"\n",
        "    X, y = np.asarray(X), np.asarray(y)\n",
        "    if X.shape[0] != y.shape[0]:\n",
        "        raise ValueError(\"X and y must match in rows\")\n",
        "\n",
        "    folds = k_fold_indices(len(y), k, shuffle, random_state)\n",
        "\n",
        "    if metric is None:\n",
        "        metric = accuracy_score if np.issubdtype(y.dtype, np.integer) else mse_score\n",
        "\n",
        "    scores = []\n",
        "    for i in range(k):\n",
        "        test_idx, train_idx = folds[i], np.hstack([folds[j] for j in range(k) if j != i])\n",
        "        model = _as_predictable(learner(X[train_idx], y[train_idx]))\n",
        "        preds = np.asarray(model.predict(X[test_idx]))\n",
        "        scores.append(float(metric(y[test_idx], preds)))\n",
        "\n",
        "    scores = np.array(scores)\n",
        "    return {\n",
        "        'fold_scores': scores,\n",
        "        'mean_score': float(scores.mean()),\n",
        "        'std_score': float(scores.std(ddof=0)),\n",
        "        'n_folds': k\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------- METRICS ----------\n",
        "\n",
        "def accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    return (np.asarray(y_true) == np.asarray(y_pred)).mean()\n",
        "\n",
        "\n",
        "def mse_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    yt, yp = np.asarray(y_true, float), np.asarray(y_pred, float)\n",
        "    return ((yt - yp) ** 2).mean()\n",
        "\n",
        "\n",
        "# ---------- LEARNERS ----------\n",
        "\n",
        "def nearest_mean_classifier(X: np.ndarray, y: np.ndarray):\n",
        "    X, y, classes = np.asarray(X), np.asarray(y), np.unique(y)\n",
        "    means = {c: X[y == c].mean(axis=0) for c in classes}\n",
        "\n",
        "    def predict(X_new):\n",
        "        return np.array([min(classes, key=lambda c: np.linalg.norm(x - means[c])) for x in np.asarray(X_new)])\n",
        "\n",
        "    return predict\n",
        "\n",
        "\n",
        "def linear_regression_closed_form(X: np.ndarray, y: np.ndarray, intercept: bool = True):\n",
        "    X, y = np.asarray(X, float), np.asarray(y, float)\n",
        "    Xd = np.hstack([np.ones((X.shape[0], 1)), X]) if intercept else X\n",
        "    theta = np.linalg.pinv(Xd).dot(y)\n",
        "\n",
        "    def predict(X_new):\n",
        "        Xn = np.asarray(X_new, float)\n",
        "        if intercept:\n",
        "            Xn = np.hstack([np.ones((Xn.shape[0], 1)), Xn])\n",
        "        return Xn.dot(theta)\n",
        "\n",
        "    return predict\n",
        "\n",
        "\n",
        "# ---------- DEMO ----------\n",
        "if __name__ == '__main__':\n",
        "    rng = np.random.default_rng(0)\n",
        "\n",
        "    # Classification\n",
        "    Xc = np.vstack([\n",
        "        rng.normal(0.0, 0.8, (50, 2)),\n",
        "        rng.normal(3.0, 0.5, (50, 2)),\n",
        "        rng.normal([0.0, 4.0], 0.6, (50, 2))\n",
        "    ])\n",
        "    yc = np.array([0]*50 + [1]*50 + [2]*50)\n",
        "    print('Nearest-mean CV:', cross_validate(Xc, yc, nearest_mean_classifier, k=5, random_state=1))\n",
        "\n",
        "    # Regression\n",
        "    Xr = rng.normal(size=(200, 3))\n",
        "    true_theta = np.array([1.5, -2.0, 0.5, 3.0])\n",
        "    yr = np.column_stack([np.ones(Xr.shape[0]), Xr]).dot(true_theta) + rng.normal(0, 0.5, 200)\n",
        "    print('Linear regression CV:', cross_validate(Xr, yr, lambda X, y: linear_regression_closed_form(X, y), k=4))\n",
        "\n",
        "    # Edge case\n",
        "    try:\n",
        "        k_fold_indices(3, k=5)\n",
        "    except ValueError as e:\n",
        "        print('Expected error:', e)\n",
        "\n",
        "    # Dummy sklearn-like model\n",
        "    class DummyModel:\n",
        "        def __init__(self, val): self.val = val\n",
        "        def predict(self, X): return np.full((X.shape[0],), self.val)\n",
        "\n",
        "    def learner_dummy(X, y): return DummyModel(int(np.round(y.mean())))\n",
        "    Xs, ys = np.arange(20).reshape(10, 2), np.array([0, 1]*5)\n",
        "    print('Dummy model CV:', cross_validate(Xs, ys, learner_dummy, k=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_5LCRx0Lg5E",
        "outputId": "c251642f-5601-477b-a1ab-64e428e03e83"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest-mean CV: {'fold_scores': array([1., 1., 1., 1., 1.]), 'mean_score': 1.0, 'std_score': 0.0, 'n_folds': 5}\n",
            "Linear regression CV: {'fold_scores': array([0.30688093, 0.33546426, 0.21518432, 0.25073411]), 'mean_score': 0.2770659051104247, 'std_score': 0.04696274412433855, 'n_folds': 4}\n",
            "Expected error: n_samples must be >= k\n",
            "Dummy model CV: {'fold_scores': array([0. , 0.5, 0.5, 0.5, 0. ]), 'mean_score': 0.3, 'std_score': 0.24494897427831783, 'n_folds': 5}\n"
          ]
        }
      ]
    }
  ]
}